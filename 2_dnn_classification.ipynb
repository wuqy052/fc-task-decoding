{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b562db1-f0c4-493d-b5ea-42e24380a40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "#import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d51a4a-ba4c-42c5-92db-655f65172706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_roi = 128\n",
    "num_tasks = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49a26b-be27-454b-8261-611f0f9f8455",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e5c17bf-b697-4a40-99ef-c3d37ece806f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tensor(sub_data):\n",
    "    \"\"\"\n",
    "    this function take each subject's connectivity dataframe, and convert them to input and label\n",
    "    returns: X = 1d-array connectivity input; y = 1d-array task label\n",
    "    \"\"\"\n",
    "    #remove self correlations\n",
    "    sub_data = sub_data.loc[sub_data.level_0 != sub_data.level_1]\n",
    "    #get only lower triangle\n",
    "    sub_data = sub_data.sort_values(by='correlation').iloc[::2, :]\n",
    "    #sanity check\n",
    "    assert(len(sub_data['correlation'])) == num_roi*(num_roi-1)/2*num_tasks\n",
    "        \n",
    "    #separate into input and label\n",
    "    mydict = sub_data.sort_values(by=['task', 'level_0', 'level_1']).groupby('task')['correlation'].apply(list)\n",
    "    labels = [i for i,v in enumerate(mydict.keys())]\n",
    "    data = [i for i in mydict]\n",
    "    #turn to tensor: input and label\n",
    "    X = torch.from_numpy(np.hstack(data).reshape(4, -1))\n",
    "    #y = torch.nn.functional.one_hot(torch.tensor(labels))\n",
    "    y = torch.tensor(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78e4bcf5-ac10-48a8-acad-92c532c945ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    this function reads all subject connectivity data and returns all inputs and labels\n",
    "    look at get tensor for specifics\n",
    "    \"\"\"\n",
    "    all_inputs = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "    for i in os.listdir('processed_data'):\n",
    "        try:\n",
    "            sub_data = pd.read_csv('processed_data/' + i, index_col=[0])\n",
    "            X, y = get_tensor(sub_data)\n",
    "            all_inputs = torch.cat([all_inputs, X])\n",
    "            all_labels = torch.cat([all_labels, y])    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #make sure they are of the same size\n",
    "    assert(torch.Tensor.size(all_inputs)[0] == torch.Tensor.size(all_labels)[0])\n",
    "    #get input and label type right\n",
    "    all_inputs = all_inputs.to(torch.float32)\n",
    "    all_labels = all_labels.type(torch.LongTensor)\n",
    "    \n",
    "    return all_inputs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f98127f-43bc-4500-9d77-43353a2d49fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs, all_labels = load_data()\n",
    "len(all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1cf5b7d-db85-4d79-a907-435b6338ee06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load subdata\n",
    "\n",
    "# sub = 'sub-10249'\n",
    "# sub_data = pd.read_csv('processed_data/' + sub + '.csv', index_col=[0])\n",
    "# #remove self correlations\n",
    "# sub_data = sub_data.loc[sub_data.level_0 != sub_data.level_1]\n",
    "# #get only lower triangle\n",
    "# sub_data = sub_data.sort_values(by='correlation').iloc[::2, :]\n",
    "# sub_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f445aa-efdc-49da-a1e4-6b11313cc0a5",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7441488-7f62-4237-9cc8-7dfa6bfe5084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        ### model\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(int(num_roi*(num_roi-1)/2), 4096),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(512, 32),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(32, num_tasks),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        ### hyperparameters\n",
    "        #batch size\n",
    "        self.batch_size = 80\n",
    "        #train epochs\n",
    "        self.num_epochs = 120\n",
    "        #learning rate\n",
    "        self.lr = 0.075\n",
    "        #l2 regularization\n",
    "        self.l2 = 0\n",
    "        #kfold stratified crossvalidation\n",
    "        self.num_folds = 5\n",
    "        \n",
    "        #optimizer\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.l2) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    def accuracy(self, pred, labels):\n",
    "        return (torch.Tensor.argmax(pred, axis=1)==labels).sum().item() / len(labels)\n",
    "    \n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "771169ae-93fd-48e8-a3bc-124273dd527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = len(train_dataloader.dataset)\n",
    "def train(model,\n",
    "          all_inputs, \n",
    "          all_labels, \n",
    "          ):\n",
    "    \n",
    "    batch_size = model.batch_size\n",
    "    batch_num = int(np.ceil(len(all_inputs)/batch_size))\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    all_loss = [] #record loss\n",
    "    \n",
    "    for epoch in range(model.num_epochs):\n",
    "        #shuffle\n",
    "        #all_inputs, all_labels = shuffle(all_inputs, all_labels, random_state = epoch)\n",
    "        accuracy = 0\n",
    "\n",
    "        # Walk through each training batch:\n",
    "        for i in range(batch_num):\n",
    "            #get batch X and y\n",
    "            batch_X = all_inputs[i*batch_size: min((i+1)*batch_size, len(all_inputs))]\n",
    "            batch_y = all_labels[i*batch_size: min((i+1)*batch_size, len(all_labels))]\n",
    "\n",
    "            # Compute prediction and loss:\n",
    "            pred = model(batch_X)\n",
    "            loss = loss_fn(pred, batch_y)\n",
    "            accuracy += model.accuracy(pred, batch_y)\n",
    "\n",
    "            # Backpropagation\n",
    "            model.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "        # Print out a status message every so often.\n",
    "        if (1+epoch)%10==0:\n",
    "            #get loss and accuracy\n",
    "            (loss, current) = (loss.item(), epoch)\n",
    "            all_loss.append(loss)\n",
    "            accuracy = accuracy / batch_num\n",
    "\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{model.num_epochs}]\")\n",
    "            print(f\"train accuracy: {accuracy:>5f}\")\n",
    "            \n",
    "    return model, all_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0991c740-de09-4883-a68e-23657c9ab3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, \n",
    "        all_inputs,\n",
    "        all_labels):\n",
    "    \n",
    "    #correct = 0\n",
    "    #total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(all_inputs)\n",
    "        accuracy = model.accuracy(outputs, all_labels)\n",
    "        # pred = torch.Tensor.argmax(outputs, axis=1)\n",
    "        # total += len(all_labels)\n",
    "        # correct += (pred == all_labels).sum().item()\n",
    "    #accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy}\")\n",
    "    \n",
    "    return accuracy, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fe54033-d5b9-4ed0-b79a-d82932148900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cross validation\n",
    "def cv(model,\n",
    "       all_inputs,\n",
    "       all_labels):\n",
    "    \n",
    "    #set up multiprocessing\n",
    "    # p = mp.Pool(processes = num_processes) \n",
    "    # p.map(cv_group, (train_indices, test_indices) in enumerate(kfold.split(all_inputs, all_labels)))\n",
    "    kfold = StratifiedKFold(n_splits=model.num_folds, shuffle=True)\n",
    "    for fold, (train_indices, test_indices) in enumerate(kfold.split(all_inputs, all_labels)):\n",
    "        print(f\"fold {fold} / {model.num_folds}\")\n",
    "        #get data\n",
    "        train_X = all_inputs[train_indices]\n",
    "        train_y = all_labels[train_indices]\n",
    "        test_X = all_inputs[test_indices]\n",
    "        test_y = all_labels[test_indices]\n",
    "\n",
    "        #Initialize the neural network\n",
    "        model = NeuralNetwork()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        #train\n",
    "        model, pred, all_loss = train(model, train_X, train_y)\n",
    "        #test\n",
    "        test_acc, outputs = test(model, test_X, test_y)\n",
    "    \n",
    "    return model, outputs, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4321479a-660f-4ecc-b81e-de2dcadec8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.385216  [    9/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.383489  [   19/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.381379  [   29/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.378439  [   39/100]\n",
      "train accuracy: 0.292857\n",
      "loss: 1.373510  [   49/100]\n",
      "train accuracy: 0.458929\n",
      "loss: 1.362621  [   59/100]\n",
      "train accuracy: 0.646429\n",
      "loss: 1.320657  [   69/100]\n",
      "train accuracy: 0.266071\n",
      "loss: 1.221604  [   79/100]\n",
      "train accuracy: 0.446429\n",
      "loss: 1.190167  [   89/100]\n",
      "train accuracy: 0.766071\n",
      "loss: 1.169870  [   99/100]\n",
      "train accuracy: 0.910714\n",
      "Validation Accuracy: 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "# test on one train and test\n",
    "model = NeuralNetwork()\n",
    "train_X = all_inputs[0:500,:]\n",
    "train_y = all_labels[0:500]\n",
    "model, all_loss, accuracy = train(model, train_X, train_y)\n",
    "\n",
    "test_X = all_inputs[500:, :]\n",
    "test_y = all_labels[500:]\n",
    "model, pred, test_acc = test(model, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a044b95-9c31-4738-a929-ed09abbba4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 / 5\n",
      "loss: 1.385378  [    9/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.384856  [   19/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.384269  [   29/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.383527  [   39/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.382506  [   49/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.381053  [   59/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.378875  [   69/120]\n",
      "train accuracy: 0.250828\n",
      "loss: 1.375256  [   79/120]\n",
      "train accuracy: 0.259582\n",
      "loss: 1.367819  [   89/120]\n",
      "train accuracy: 0.321559\n",
      "loss: 1.341822  [   99/120]\n",
      "train accuracy: 0.349956\n",
      "loss: 1.221852  [  109/120]\n",
      "train accuracy: 0.487456\n",
      "loss: 1.133414  [  119/120]\n",
      "train accuracy: 0.649260\n",
      "Validation Accuracy: 0.48854961832061067\n",
      "fold 1 / 5\n",
      "loss: 1.383261  [    9/120]\n",
      "train accuracy: 0.310932\n",
      "loss: 1.382432  [   19/120]\n",
      "train accuracy: 0.337631\n",
      "loss: 1.381486  [   29/120]\n",
      "train accuracy: 0.364329\n",
      "loss: 1.380283  [   39/120]\n",
      "train accuracy: 0.400044\n",
      "loss: 1.378584  [   49/120]\n",
      "train accuracy: 0.428441\n",
      "loss: 1.375966  [   59/120]\n",
      "train accuracy: 0.453441\n",
      "loss: 1.371346  [   69/120]\n",
      "train accuracy: 0.480226\n",
      "loss: 1.361634  [   79/120]\n",
      "train accuracy: 0.499782\n",
      "loss: 1.331446  [   89/120]\n",
      "train accuracy: 0.505139\n",
      "loss: 1.177808  [   99/120]\n",
      "train accuracy: 0.505139\n",
      "loss: 1.031224  [  109/120]\n",
      "train accuracy: 0.718728\n",
      "loss: 0.919985  [  119/120]\n",
      "train accuracy: 0.892857\n",
      "Validation Accuracy: 0.37404580152671757\n",
      "fold 2 / 5\n",
      "loss: 1.386304  [    9/120]\n",
      "train accuracy: 0.249915\n",
      "loss: 1.385345  [   19/120]\n",
      "train accuracy: 0.251701\n",
      "loss: 1.384183  [   29/120]\n",
      "train accuracy: 0.292262\n",
      "loss: 1.382675  [   39/120]\n",
      "train accuracy: 0.416412\n",
      "loss: 1.380535  [   49/120]\n",
      "train accuracy: 0.484099\n",
      "loss: 1.377146  [   59/120]\n",
      "train accuracy: 0.455697\n",
      "loss: 1.370571  [   69/120]\n",
      "train accuracy: 0.391752\n",
      "loss: 1.347299  [   79/120]\n",
      "train accuracy: 0.264031\n",
      "loss: 1.253471  [   89/120]\n",
      "train accuracy: 0.613095\n",
      "loss: 1.194663  [   99/120]\n",
      "train accuracy: 0.517347\n",
      "loss: 1.115258  [  109/120]\n",
      "train accuracy: 0.724235\n",
      "loss: 0.809155  [  119/120]\n",
      "train accuracy: 1.000000\n",
      "Validation Accuracy: 0.4153846153846154\n",
      "fold 3 / 5\n",
      "loss: 1.384697  [    9/120]\n",
      "train accuracy: 0.249915\n",
      "loss: 1.383917  [   19/120]\n",
      "train accuracy: 0.249915\n",
      "loss: 1.382905  [   29/120]\n",
      "train accuracy: 0.350850\n",
      "loss: 1.381323  [   39/120]\n",
      "train accuracy: 0.476786\n",
      "loss: 1.378399  [   49/120]\n",
      "train accuracy: 0.473214\n",
      "loss: 1.372243  [   59/120]\n",
      "train accuracy: 0.394813\n",
      "loss: 1.347929  [   69/120]\n",
      "train accuracy: 0.269218\n",
      "loss: 1.237833  [   79/120]\n",
      "train accuracy: 0.443027\n",
      "loss: 1.182566  [   89/120]\n",
      "train accuracy: 0.498044\n",
      "loss: 1.164801  [   99/120]\n",
      "train accuracy: 0.499830\n",
      "loss: 1.139246  [  109/120]\n",
      "train accuracy: 0.707568\n",
      "loss: 0.993387  [  119/120]\n",
      "train accuracy: 0.748129\n",
      "Validation Accuracy: 0.3384615384615385\n",
      "fold 4 / 5\n",
      "loss: 1.385372  [    9/120]\n",
      "train accuracy: 0.262245\n",
      "loss: 1.384304  [   19/120]\n",
      "train accuracy: 0.278146\n",
      "loss: 1.383135  [   29/120]\n",
      "train accuracy: 0.313350\n",
      "loss: 1.381749  [   39/120]\n",
      "train accuracy: 0.348724\n",
      "loss: 1.380008  [   49/120]\n",
      "train accuracy: 0.381973\n",
      "loss: 1.377584  [   59/120]\n",
      "train accuracy: 0.477551\n",
      "loss: 1.373608  [   69/120]\n",
      "train accuracy: 0.633673\n",
      "loss: 1.365904  [   79/120]\n",
      "train accuracy: 0.694048\n",
      "loss: 1.341460  [   89/120]\n",
      "train accuracy: 0.418793\n",
      "loss: 1.226750  [   99/120]\n",
      "train accuracy: 0.766922\n",
      "loss: 1.127392  [  109/120]\n",
      "train accuracy: 0.980527\n",
      "loss: 0.851126  [  119/120]\n",
      "train accuracy: 1.000000\n",
      "Validation Accuracy: 0.45384615384615384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(NeuralNetwork(\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (linear_relu_stack): Sequential(\n",
       "     (0): Linear(in_features=8128, out_features=4096, bias=True)\n",
       "     (1): LeakyReLU(negative_slope=0.1)\n",
       "     (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "     (3): LeakyReLU(negative_slope=0.1)\n",
       "     (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "     (5): LeakyReLU(negative_slope=0.1)\n",
       "     (6): Linear(in_features=512, out_features=32, bias=True)\n",
       "     (7): LeakyReLU(negative_slope=0.1)\n",
       "     (8): Linear(in_features=32, out_features=4, bias=True)\n",
       "     (9): Softmax(dim=1)\n",
       "   )\n",
       " ),\n",
       " tensor([[3.6233e-01, 4.1442e-01, 1.3699e-01, 8.6252e-02],\n",
       "         [3.7354e-01, 6.9289e-02, 3.4270e-01, 2.1447e-01],\n",
       "         [4.6834e-01, 1.1806e-01, 2.3133e-01, 1.8227e-01],\n",
       "         [3.9202e-01, 8.0767e-02, 1.7623e-01, 3.5098e-01],\n",
       "         [4.3203e-01, 1.4018e-01, 2.1141e-01, 2.1638e-01],\n",
       "         [5.0410e-01, 1.1286e-01, 1.8746e-01, 1.9558e-01],\n",
       "         [3.4323e-01, 5.5678e-02, 3.0253e-01, 2.9856e-01],\n",
       "         [4.2285e-01, 1.3901e-01, 2.6697e-01, 1.7117e-01],\n",
       "         [3.4851e-01, 7.9645e-02, 2.5213e-01, 3.1972e-01],\n",
       "         [4.0442e-01, 3.4413e-01, 1.2229e-01, 1.2915e-01],\n",
       "         [3.5552e-01, 8.7351e-02, 3.4036e-01, 2.1677e-01],\n",
       "         [1.3662e-01, 7.9761e-01, 3.6783e-02, 2.8989e-02],\n",
       "         [3.6592e-01, 1.2697e-01, 2.7676e-01, 2.3035e-01],\n",
       "         [3.1307e-01, 3.2719e-02, 2.9557e-01, 3.5864e-01],\n",
       "         [2.2012e-03, 9.9773e-01, 3.9659e-05, 3.2488e-05],\n",
       "         [5.3833e-01, 6.9501e-02, 2.0640e-01, 1.8577e-01],\n",
       "         [2.7511e-01, 3.1006e-02, 2.5653e-01, 4.3735e-01],\n",
       "         [4.4915e-01, 3.3390e-01, 1.1235e-01, 1.0459e-01],\n",
       "         [3.4325e-01, 6.8048e-02, 3.1716e-01, 2.7155e-01],\n",
       "         [3.3963e-01, 7.5518e-02, 2.4611e-01, 3.3875e-01],\n",
       "         [3.1448e-01, 2.9229e-02, 3.7138e-01, 2.8491e-01],\n",
       "         [3.1524e-03, 9.9672e-01, 2.5919e-05, 9.7691e-05],\n",
       "         [2.8754e-01, 5.3298e-01, 1.1236e-01, 6.7121e-02],\n",
       "         [3.9757e-01, 2.7749e-01, 1.4253e-01, 1.8240e-01],\n",
       "         [4.6056e-01, 2.7366e-01, 1.3443e-01, 1.3135e-01],\n",
       "         [3.9972e-01, 4.2628e-02, 2.9149e-01, 2.6616e-01],\n",
       "         [2.9972e-01, 3.6691e-02, 2.5075e-01, 4.1284e-01],\n",
       "         [4.0678e-01, 6.3809e-02, 2.5477e-01, 2.7464e-01],\n",
       "         [4.7759e-01, 1.8560e-01, 1.6497e-01, 1.7183e-01],\n",
       "         [2.5980e-01, 5.8626e-01, 9.7977e-02, 5.5963e-02],\n",
       "         [3.4932e-01, 2.8337e-02, 2.5955e-01, 3.6280e-01],\n",
       "         [4.9125e-01, 2.0548e-01, 9.8761e-02, 2.0451e-01],\n",
       "         [1.0714e-01, 8.7729e-01, 1.0910e-02, 4.6596e-03],\n",
       "         [4.2348e-01, 1.0700e-01, 2.2393e-01, 2.4558e-01],\n",
       "         [1.7532e-02, 9.8088e-01, 7.5265e-04, 8.4009e-04],\n",
       "         [4.0633e-01, 2.8031e-01, 1.5007e-01, 1.6329e-01],\n",
       "         [4.4217e-01, 1.2537e-01, 2.3799e-01, 1.9447e-01],\n",
       "         [2.6906e-01, 4.7523e-01, 1.2549e-01, 1.3022e-01],\n",
       "         [3.4186e-01, 5.6372e-02, 3.2620e-01, 2.7557e-01],\n",
       "         [4.5013e-01, 4.9625e-02, 2.0641e-01, 2.9383e-01],\n",
       "         [3.8249e-01, 1.1392e-01, 2.5971e-01, 2.4388e-01],\n",
       "         [3.4201e-01, 4.4003e-01, 1.3062e-01, 8.7342e-02],\n",
       "         [3.9833e-01, 7.0327e-02, 2.3041e-01, 3.0093e-01],\n",
       "         [3.0269e-01, 4.4237e-02, 2.4259e-01, 4.1048e-01],\n",
       "         [3.7253e-01, 4.0686e-02, 2.4179e-01, 3.4499e-01],\n",
       "         [4.2045e-01, 6.2631e-02, 2.7476e-01, 2.4216e-01],\n",
       "         [3.4802e-01, 5.7295e-01, 3.5013e-02, 4.4022e-02],\n",
       "         [3.0796e-01, 4.8145e-02, 2.6008e-01, 3.8382e-01],\n",
       "         [2.9404e-01, 4.1172e-02, 3.0761e-01, 3.5718e-01],\n",
       "         [5.5685e-02, 9.3696e-01, 1.8335e-03, 5.5199e-03],\n",
       "         [3.6845e-02, 9.5943e-01, 1.8516e-03, 1.8706e-03],\n",
       "         [4.0355e-01, 2.5768e-01, 1.8655e-01, 1.5223e-01],\n",
       "         [2.3845e-01, 6.5425e-01, 5.1170e-02, 5.6132e-02],\n",
       "         [3.4721e-01, 3.8280e-02, 2.1034e-01, 4.0417e-01],\n",
       "         [8.9025e-02, 8.9894e-01, 6.1396e-03, 5.8970e-03],\n",
       "         [3.4360e-01, 4.8487e-01, 8.0251e-02, 9.1275e-02],\n",
       "         [3.5613e-01, 1.1683e-01, 3.2037e-01, 2.0668e-01],\n",
       "         [4.0812e-01, 4.3872e-01, 8.1853e-02, 7.1309e-02],\n",
       "         [5.1827e-01, 2.1293e-01, 1.2382e-01, 1.4497e-01],\n",
       "         [3.2659e-01, 3.9672e-01, 1.3427e-01, 1.4242e-01],\n",
       "         [3.7352e-01, 3.3037e-01, 1.7033e-01, 1.2579e-01],\n",
       "         [5.9143e-02, 9.2974e-01, 7.5882e-03, 3.5284e-03],\n",
       "         [1.1001e-01, 8.4959e-01, 1.4926e-02, 2.5472e-02],\n",
       "         [4.2447e-01, 4.2480e-02, 2.9203e-01, 2.4101e-01],\n",
       "         [6.8006e-02, 9.2171e-01, 3.6350e-03, 6.6482e-03],\n",
       "         [4.1415e-01, 3.3770e-01, 1.2137e-01, 1.2678e-01],\n",
       "         [3.7933e-01, 7.6306e-02, 3.3586e-01, 2.0850e-01],\n",
       "         [3.4255e-01, 3.6434e-02, 2.6350e-01, 3.5752e-01],\n",
       "         [3.4773e-01, 5.1039e-02, 1.8802e-01, 4.1321e-01],\n",
       "         [1.1486e-01, 8.3108e-01, 3.2055e-02, 2.2007e-02],\n",
       "         [3.8235e-01, 1.6060e-01, 2.5338e-01, 2.0367e-01],\n",
       "         [2.5385e-01, 6.5680e-01, 4.1095e-02, 4.8261e-02],\n",
       "         [3.7227e-01, 3.8507e-01, 1.2787e-01, 1.1479e-01],\n",
       "         [4.5397e-01, 2.3292e-01, 1.1508e-01, 1.9803e-01],\n",
       "         [3.4603e-01, 3.6856e-01, 1.2779e-01, 1.5762e-01],\n",
       "         [3.4315e-01, 3.1397e-01, 1.7620e-01, 1.6668e-01],\n",
       "         [3.7994e-01, 7.1502e-02, 3.6224e-01, 1.8631e-01],\n",
       "         [3.8155e-01, 5.8734e-02, 2.7827e-01, 2.8145e-01],\n",
       "         [4.3525e-01, 8.1120e-02, 2.3253e-01, 2.5110e-01],\n",
       "         [3.7789e-01, 4.3510e-01, 8.2730e-02, 1.0428e-01],\n",
       "         [4.2026e-01, 7.4796e-02, 2.8168e-01, 2.2326e-01],\n",
       "         [3.1240e-03, 9.9673e-01, 4.8483e-05, 9.3155e-05],\n",
       "         [3.1263e-01, 4.7184e-02, 3.3063e-01, 3.0955e-01],\n",
       "         [3.6185e-01, 1.3480e-01, 3.0168e-01, 2.0166e-01],\n",
       "         [3.9356e-01, 2.3151e-01, 1.7362e-01, 2.0131e-01],\n",
       "         [2.9291e-01, 3.9996e-02, 2.5922e-01, 4.0787e-01],\n",
       "         [3.4596e-01, 8.4586e-02, 2.2844e-01, 3.4102e-01],\n",
       "         [3.2449e-01, 4.6073e-02, 2.4406e-01, 3.8538e-01],\n",
       "         [3.5606e-01, 3.5881e-02, 3.6541e-01, 2.4265e-01],\n",
       "         [3.3277e-01, 6.4568e-02, 3.1792e-01, 2.8475e-01],\n",
       "         [3.2426e-01, 4.2530e-02, 2.6294e-01, 3.7027e-01],\n",
       "         [4.1328e-01, 4.5725e-02, 3.0733e-01, 2.3367e-01],\n",
       "         [3.9122e-01, 1.2647e-01, 3.2729e-01, 1.5502e-01],\n",
       "         [5.0012e-02, 9.4094e-01, 5.4640e-03, 3.5838e-03],\n",
       "         [3.2650e-01, 5.1418e-01, 8.1736e-02, 7.7587e-02],\n",
       "         [1.7610e-01, 7.7373e-01, 3.2774e-02, 1.7399e-02],\n",
       "         [3.1748e-01, 3.9858e-02, 4.0313e-01, 2.3953e-01],\n",
       "         [3.7140e-01, 2.7443e-01, 2.0578e-01, 1.4838e-01],\n",
       "         [1.5906e-03, 9.9838e-01, 1.5466e-05, 1.2547e-05],\n",
       "         [3.7802e-01, 8.2263e-02, 2.1385e-01, 3.2587e-01],\n",
       "         [3.6205e-01, 3.0186e-01, 1.3676e-01, 1.9933e-01],\n",
       "         [3.7814e-01, 1.6192e-01, 1.8895e-01, 2.7099e-01],\n",
       "         [8.8548e-02, 8.9343e-01, 5.7418e-03, 1.2285e-02],\n",
       "         [3.0679e-01, 3.6627e-01, 1.2734e-01, 1.9960e-01],\n",
       "         [3.6284e-02, 9.5511e-01, 2.5090e-03, 6.0987e-03],\n",
       "         [4.1953e-01, 3.4148e-01, 1.1818e-01, 1.2081e-01],\n",
       "         [3.3977e-01, 6.5599e-02, 3.1939e-01, 2.7524e-01],\n",
       "         [3.7116e-01, 3.4500e-02, 3.5767e-01, 2.3667e-01],\n",
       "         [3.1805e-01, 5.2913e-02, 2.5362e-01, 3.7542e-01],\n",
       "         [2.9364e-01, 3.8144e-02, 3.8266e-01, 2.8555e-01],\n",
       "         [3.7137e-01, 3.4836e-01, 1.3018e-01, 1.5010e-01],\n",
       "         [3.6305e-01, 1.2175e-01, 1.7231e-01, 3.4289e-01],\n",
       "         [4.1895e-01, 1.9445e-01, 1.2269e-01, 2.6391e-01],\n",
       "         [4.6651e-01, 1.9625e-01, 1.7496e-01, 1.6227e-01],\n",
       "         [4.9909e-01, 1.6860e-01, 1.3309e-01, 1.9922e-01],\n",
       "         [4.5178e-01, 4.2079e-02, 2.5652e-01, 2.4962e-01],\n",
       "         [1.8950e-01, 7.4851e-01, 2.7471e-02, 3.4523e-02],\n",
       "         [2.8436e-01, 4.8055e-02, 3.5131e-01, 3.1627e-01],\n",
       "         [4.4736e-01, 1.2993e-01, 2.1050e-01, 2.1221e-01],\n",
       "         [9.3839e-02, 8.9266e-01, 4.6161e-03, 8.8877e-03],\n",
       "         [3.4180e-01, 8.9531e-02, 2.3160e-01, 3.3707e-01],\n",
       "         [2.9156e-01, 3.7032e-02, 2.7350e-01, 3.9791e-01],\n",
       "         [4.0528e-01, 4.6536e-02, 3.0669e-01, 2.4150e-01],\n",
       "         [4.0765e-01, 3.4622e-02, 2.2259e-01, 3.3514e-01],\n",
       "         [3.3269e-01, 3.0064e-02, 2.9992e-01, 3.3733e-01],\n",
       "         [4.3790e-01, 1.4898e-01, 2.2456e-01, 1.8855e-01],\n",
       "         [4.3737e-01, 1.1961e-01, 2.1865e-01, 2.2437e-01],\n",
       "         [4.0026e-01, 1.2134e-01, 2.3563e-01, 2.4278e-01],\n",
       "         [3.1175e-01, 4.4937e-02, 3.9525e-01, 2.4806e-01],\n",
       "         [5.3170e-01, 1.7183e-01, 1.6546e-01, 1.3101e-01]]),\n",
       " 0.45384615384615384)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on cv\n",
    "model = NeuralNetwork()\n",
    "cv(model, all_inputs, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a3e6a-33c3-4254-8dba-9ea6ae2db7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b11f0f-e746-411d-b556-24ca4d58ffd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for fold, (train_indices, val_indices) in enumerate(kfold.split(all_inputs, all_labels)):\n",
    "#     print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "    \n",
    "#     # Create data loaders for training and validation sets\n",
    "#     train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "#     train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    \n",
    "#     val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "#     val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "#     # Initialize the neural network\n",
    "#     model = NeuralNetwork()\n",
    "    \n",
    "#     # Define loss function and optimizer\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for inputs, labels in train_loader:\n",
    "#             # Initialize optimizer\n",
    "#             optimizer.zero_grad()\n",
    "#             # Compute prediction and loss:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Backpropagation\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss}\")\n",
    "        \n",
    "#         # Validation loop\n",
    "#         model.eval()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         accuracy = correct / total\n",
    "#         print(f\"Validation Accuracy: {accuracy}\")\n",
    "#         print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
