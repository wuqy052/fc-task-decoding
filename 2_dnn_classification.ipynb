{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b562db1-f0c4-493d-b5ea-42e24380a40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d51a4a-ba4c-42c5-92db-655f65172706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_roi = 128\n",
    "num_tasks = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49a26b-be27-454b-8261-611f0f9f8455",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5c17bf-b697-4a40-99ef-c3d37ece806f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tensor(sub_data):\n",
    "    \"\"\"\n",
    "    this function take each subject's connectivity dataframe, and convert them to input and label\n",
    "    returns: X = 1d-array connectivity input; y = 1d-array task label\n",
    "    \"\"\"\n",
    "    #remove self correlations\n",
    "    sub_data = sub_data.loc[sub_data.level_0 != sub_data.level_1]\n",
    "    #get only lower triangle\n",
    "    sub_data = sub_data.sort_values(by='correlation').iloc[::2, :]\n",
    "    #sanity check\n",
    "    assert(len(sub_data['correlation'])) == num_roi*(num_roi-1)/2*num_tasks\n",
    "        \n",
    "    #separate into input and label\n",
    "    mydict = sub_data.sort_values(by=['task', 'level_0', 'level_1']).groupby('task')['correlation'].apply(list)\n",
    "    labels = [i for i,v in enumerate(mydict.keys())]\n",
    "    data = [i for i in mydict]\n",
    "    #turn to tensor: input and label\n",
    "    X = torch.from_numpy(np.hstack(data).reshape(4, -1))\n",
    "    #y = torch.nn.functional.one_hot(torch.tensor(labels))\n",
    "    y = torch.tensor(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e4bcf5-ac10-48a8-acad-92c532c945ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    this function reads all subject connectivity data and returns all inputs and labels\n",
    "    look at get tensor for specifics\n",
    "    \"\"\"\n",
    "    all_inputs = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "    for i in os.listdir('processed_data'):\n",
    "        try:\n",
    "            sub_data = pd.read_csv('processed_data/' + i, index_col=[0])\n",
    "            X, y = get_tensor(sub_data)\n",
    "            all_inputs = torch.cat([all_inputs, X])\n",
    "            all_labels = torch.cat([all_labels, y])    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #make sure they are of the same size\n",
    "    assert(torch.Tensor.size(all_inputs)[0] == torch.Tensor.size(all_labels)[0])\n",
    "    #get input and label type right\n",
    "    all_inputs = all_inputs.to(torch.float32)\n",
    "    all_labels = all_labels.type(torch.LongTensor)\n",
    "    \n",
    "    return all_inputs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f98127f-43bc-4500-9d77-43353a2d49fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs, all_labels = load_data()\n",
    "len(all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1cf5b7d-db85-4d79-a907-435b6338ee06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load subdata\n",
    "\n",
    "# sub = 'sub-10249'\n",
    "# sub_data = pd.read_csv('processed_data/' + sub + '.csv', index_col=[0])\n",
    "# #remove self correlations\n",
    "# sub_data = sub_data.loc[sub_data.level_0 != sub_data.level_1]\n",
    "# #get only lower triangle\n",
    "# sub_data = sub_data.sort_values(by='correlation').iloc[::2, :]\n",
    "# sub_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f445aa-efdc-49da-a1e4-6b11313cc0a5",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7441488-7f62-4237-9cc8-7dfa6bfe5084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        ### model\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(int(num_roi*(num_roi-1)/2), 4096),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(512, 32),\n",
    "            torch.nn.LeakyReLU(0.1),\n",
    "            torch.nn.Linear(32, num_tasks),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        ### hyperparameters\n",
    "        #batch size\n",
    "        self.batch_size = 80\n",
    "        #train epochs\n",
    "        self.num_epochs = 100\n",
    "        #learning rate\n",
    "        self.lr = 0.07\n",
    "        #l2 regularization\n",
    "        self.l2 = 0\n",
    "        #kfold stratified crossvalidation\n",
    "        self.num_folds = 5\n",
    "        \n",
    "        #optimizer\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.l2) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    def accuracy(self, pred, labels):\n",
    "        return (torch.Tensor.argmax(pred, axis=1)==labels).sum().item() / len(labels)\n",
    "    \n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771169ae-93fd-48e8-a3bc-124273dd527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = len(train_dataloader.dataset)\n",
    "def train(model,\n",
    "          all_inputs, \n",
    "          all_labels, \n",
    "          ):\n",
    "    \n",
    "    batch_size = model.batch_size\n",
    "    batch_num = int(np.ceil(len(all_inputs)/batch_size))\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    all_loss = [] #record loss\n",
    "    \n",
    "    for epoch in range(model.num_epochs):\n",
    "        #shuffle\n",
    "        #all_inputs, all_labels = shuffle(all_inputs, all_labels, random_state = epoch)\n",
    "        accuracy = 0\n",
    "\n",
    "        # Walk through each training batch:\n",
    "        for i in range(batch_num):\n",
    "            #get batch X and y\n",
    "            batch_X = all_inputs[i*batch_size: min((i+1)*batch_size, len(all_inputs))]\n",
    "            batch_y = all_labels[i*batch_size: min((i+1)*batch_size, len(all_labels))]\n",
    "\n",
    "            # Compute prediction and loss:\n",
    "            pred = model(batch_X)\n",
    "            loss = loss_fn(pred, batch_y)\n",
    "            accuracy += model.accuracy(pred, batch_y)\n",
    "\n",
    "            # Backpropagation\n",
    "            model.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "        # Print out a status message every so often.\n",
    "        if (1+epoch)%10==0:\n",
    "            #get loss and accuracy\n",
    "            (loss, current) = (loss.item(), epoch)\n",
    "            all_loss.append(loss)\n",
    "            accuracy = accuracy / batch_num\n",
    "\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{model.num_epochs}]\")\n",
    "            print(f\"train accuracy: {accuracy:>5f}\")\n",
    "            \n",
    "    return model, all_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0991c740-de09-4883-a68e-23657c9ab3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, \n",
    "        all_inputs,\n",
    "        all_labels):\n",
    "    \n",
    "    #correct = 0\n",
    "    #total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(all_inputs)\n",
    "        accuracy = model.accuracy(outputs, all_labels)\n",
    "        # pred = torch.Tensor.argmax(outputs, axis=1)\n",
    "        # total += len(all_labels)\n",
    "        # correct += (pred == all_labels).sum().item()\n",
    "    #accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy}\")\n",
    "    \n",
    "    return accuracy, outputs, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe54033-d5b9-4ed0-b79a-d82932148900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cross validation\n",
    "def cv(model,\n",
    "       all_inputs,\n",
    "       all_labels):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=model.num_folds, shuffle=True)\n",
    "    for fold, (train_indices, test_indices) in enumerate(kfold.split(all_inputs, all_labels)):\n",
    "        print(f\"fold {fold} / {model.num_folds}\")\n",
    "        #get data\n",
    "        train_X = all_inputs[train_indices]\n",
    "        train_y = all_labels[train_indices]\n",
    "        test_X = all_inputs[test_indices]\n",
    "        test_y = all_labels[test_indices]\n",
    "\n",
    "        #Initialize the neural network\n",
    "        model = NeuralNetwork()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        #train\n",
    "        model, pred, all_loss = train(model, train_X, train_y)\n",
    "        #test\n",
    "        acc, pred = test(model, test_X, test_y)\n",
    "    \n",
    "    return model, pred, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b96d63-7b5e-4f4c-82ee-9e70477ebf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4321479a-660f-4ecc-b81e-de2dcadec8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.385216  [    9/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.383489  [   19/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.381379  [   29/100]\n",
      "train accuracy: 0.250000\n",
      "loss: 1.378439  [   39/100]\n",
      "train accuracy: 0.292857\n",
      "loss: 1.373510  [   49/100]\n",
      "train accuracy: 0.458929\n",
      "loss: 1.362621  [   59/100]\n",
      "train accuracy: 0.646429\n",
      "loss: 1.320657  [   69/100]\n",
      "train accuracy: 0.266071\n",
      "loss: 1.221604  [   79/100]\n",
      "train accuracy: 0.446429\n",
      "loss: 1.190167  [   89/100]\n",
      "train accuracy: 0.766071\n",
      "loss: 1.169870  [   99/100]\n",
      "train accuracy: 0.910714\n",
      "Validation Accuracy: 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "# test on one train and test\n",
    "model = NeuralNetwork()\n",
    "train_X = all_inputs[0:500,:]\n",
    "train_y = all_labels[0:500]\n",
    "model, all_loss, accuracy = train(model, train_X, train_y)\n",
    "\n",
    "test_X = all_inputs[500:, :]\n",
    "test_y = all_labels[500:]\n",
    "model, pred, test_acc = test(model, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a044b95-9c31-4738-a929-ed09abbba4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 / 10\n",
      "loss: 1.370776  [    9/100]\n",
      "train accuracy: 0.021875\n",
      "loss: 1.332931  [   19/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 1.288787  [   29/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 1.226865  [   39/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 1.052642  [   49/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 0.759798  [   59/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 0.743818  [   69/100]\n",
      "train accuracy: 0.054844\n",
      "loss: 0.743668  [   79/100]\n",
      "train accuracy: 0.056094\n",
      "loss: 0.743668  [   89/100]\n",
      "train accuracy: 0.077812\n",
      "loss: 0.743668  [   99/100]\n",
      "train accuracy: 0.100000\n",
      "Validation Accuracy: 0.2698412698412698\n",
      "fold 1 / 10\n",
      "loss: 1.349455  [    9/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 1.273857  [   19/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 0.948040  [   29/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 0.750929  [   39/100]\n",
      "train accuracy: 0.034219\n",
      "loss: 0.743692  [   49/100]\n",
      "train accuracy: 0.042188\n",
      "loss: 0.743668  [   59/100]\n",
      "train accuracy: 0.056094\n",
      "loss: 0.743668  [   69/100]\n",
      "train accuracy: 0.066250\n",
      "loss: 0.743668  [   79/100]\n",
      "train accuracy: 0.078125\n",
      "loss: 0.743668  [   89/100]\n",
      "train accuracy: 0.100000\n",
      "loss: 0.743668  [   99/100]\n",
      "train accuracy: 0.100000\n",
      "Validation Accuracy: 0.2222222222222222\n",
      "fold 2 / 10\n"
     ]
    }
   ],
   "source": [
    "#test on cv\n",
    "model = NeuralNetwork()\n",
    "cv(model, all_inputs, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a3e6a-33c3-4254-8dba-9ea6ae2db7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b11f0f-e746-411d-b556-24ca4d58ffd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for fold, (train_indices, val_indices) in enumerate(kfold.split(all_inputs, all_labels)):\n",
    "#     print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "    \n",
    "#     # Create data loaders for training and validation sets\n",
    "#     train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "#     train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    \n",
    "#     val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "#     val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "#     # Initialize the neural network\n",
    "#     model = NeuralNetwork()\n",
    "    \n",
    "#     # Define loss function and optimizer\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for inputs, labels in train_loader:\n",
    "#             # Initialize optimizer\n",
    "#             optimizer.zero_grad()\n",
    "#             # Compute prediction and loss:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             # Backpropagation\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss}\")\n",
    "        \n",
    "#         # Validation loop\n",
    "#         model.eval()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         accuracy = correct / total\n",
    "#         print(f\"Validation Accuracy: {accuracy}\")\n",
    "#         print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
