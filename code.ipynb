{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea5db4e-e723-404c-b090-83aa908a8d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4497bd1-976a-4d24-af6a-415acddbf9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load subject data downloaded from local computer and uploaded onto notebook \n",
    "img = nib.load('sub-10274_task-bart_bold_space-MNI152NLin2009cAsym_preproc.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6904a-b923-45c7-bb65-64cedb8a7c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_1 = image.index_img(img,1)\n",
    "plotting.view_img(img_1, threshold=None, bg_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a78932-a421-4799-af08-c1933c958536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbd203-6c5f-46f4-8ef7-5796cc2a3bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "msdl_atlas = datasets.fetch_atlas_msdl()\n",
    "\n",
    "msdl_coords = msdl_atlas.region_coords\n",
    "n_regions = len(msdl_coords)\n",
    "\n",
    "print(f'MSDL has {n_regions} ROIs, part of the following networks :\\n{np.unique(msdl_atlas.networks)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e2641-a9f2-4be9-97e4-40c0dcc2644b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotting.plot_prob_atlas(msdl_atlas.maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ddc76-4e28-43eb-9095-b3cc58c68e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nilearn import maskers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36345c-ed76-45e5-8cf0-72bb96d0a4ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masker = maskers.NiftiMapsMasker(\n",
    "    msdl_atlas.maps, resampling_target=\"data\",\n",
    "    t_r=2, detrend=True,\n",
    "    low_pass=0.1, high_pass=0.01).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc37db4-712a-48a9-8c17-e88fd617a77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi_time_series = masker.transform(img)\n",
    "roi_time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fc54e-52e6-4f70-9f47-04af3c70ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connnectome -- functional connectivity (pairwise correlations between ROIs)\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform([roi_time_series])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaef3a-86ce-45c0-8e5c-7760b7569832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "plotting.plot_matrix(correlation_matrix, labels=msdl_atlas.labels,\n",
    "                     vmax=0.8, vmin=-0.8, colorbar=True)\n",
    "\n",
    "#can see functional connectivity as defined by correlation by all 39 ROIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72061ba3-c14b-4e2e-a127-5e693791d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can view as embedded connectome \n",
    "\n",
    "plotting.view_connectome(correlation_matrix, edge_threshold=0.2,\n",
    "                         node_coords=msdl_atlas.region_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf0a8b-812b-411e-96fb-f04191b82261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We threshold to keep only the 20% of edges with the highest value\n",
    "# because the graph is very dense\n",
    "plotting.plot_connectome(\n",
    "    correlation_matrix, msdl_coords, edge_threshold=\"80%\", colorbar=True\n",
    ")\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41ab25-b20d-49f2-bc49-0e7dcbffb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need functional connectivity data and labels and then use them\n",
    "#as the inputs to train DNN below\n",
    "\n",
    "#then use pairwise comparison between tasks of interest \n",
    "#(e.g., risky decision making via BART vs. response inhibition via SST)\n",
    "#goal: can we classify task comparison with high accuracy by using a DNN?\n",
    "#if we can find high classification accuracy with decoded features considered\n",
    "#highly salient by decoder, this could potentially show correlations between diff\n",
    "#networks that may be commonly known for their activation during task performance\n",
    "\n",
    "\n",
    "#then we reshape the correlation matrix into a flat vector, but when we plot\n",
    "#we can reshape it to original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9d09c-9b59-4d19-a055-d4a45c49ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-Tuning and Optimization:\n",
    "#Depending on the performance of your initial model, \n",
    "#you might need to fine-tune various hyperparameters, \n",
    "#adjust the network architecture, or use regularization techniques to prevent overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2e76b-70ef-49bb-887d-558e585794d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#next need to get feature salient scores\n",
    "#install deeplift library in terminal\n",
    "#used pip install deeplift \n",
    "\n",
    "#from deeplift.layers import NonlinearMxtsMode\n",
    "#from deeplift.conversion import kerasapi_conversion as kc\n",
    "#from deeplift.blobs import NonlinearMxtsMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa18d886-d458-495b-b506-82216135234f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "import deeplift\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import load_model\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "\n",
    "import h5py\n",
    "import deepexplain\n",
    "import matplotlib\n",
    "import skimage\n",
    "import scipy\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa07da1-68d2-4856-84fc-154ca50fb86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import DeepExplain to draw saliency maps -- compatibility issue between TensorFlow versions \n",
    "#and DeepExplain library so had to bypass it by adding a line of code in DeepExplain library on \n",
    "#jupyter notebook in home dir. asked terminal to reinstall it using updated code and restarted\n",
    "#kernel and worked afterwards\n",
    "from deepexplain.tensorflow import DeepExplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036b5c5f-843b-4913-b8a5-a47fecc35edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacab2af-acbc-4d50-b399-70687652a403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the DNN model\n",
    "keras_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images to a 1D vector\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for the different clothing items\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ac80f1-0345-4bcb-a8e0-ed628f4c6fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "keras_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9ac107-441b-40c3-b629-3f18cf000bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 19:04:41.951999: W tensorflow/c/c_api.cc:291] Operation '{name:'dense/kernel/Assign' id:14 op device:{requested: '', assigned: ''} def:{{{node dense/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense/kernel, dense/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/training_v1.py:2333: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-08-18 19:04:45.442895: W tensorflow/c/c_api.cc:291] Operation '{name:'loss/mul' id:125 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/dense_2_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5018 - acc: 0.8216 - val_loss: 0.4139 - val_acc: 0.8503\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3723 - acc: 0.8648 - val_loss: 0.3905 - val_acc: 0.8577\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3319 - acc: 0.8795 - val_loss: 0.3679 - val_acc: 0.8696\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3080 - acc: 0.8870 - val_loss: 0.3596 - val_acc: 0.8676\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2907 - acc: 0.8924 - val_loss: 0.3569 - val_acc: 0.8710\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2781 - acc: 0.8965 - val_loss: 0.3432 - val_acc: 0.8782\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2655 - acc: 0.9019 - val_loss: 0.3315 - val_acc: 0.8800\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2534 - acc: 0.9048 - val_loss: 0.3392 - val_acc: 0.8784\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2453 - acc: 0.9083 - val_loss: 0.3344 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2357 - acc: 0.9120 - val_loss: 0.3323 - val_acc: 0.8788\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = keras_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df8ec5d-af7a-454f-891e-21e008510d71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8788\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = keras_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41faa1-c74e-4c67-8c5f-88db2b4ba800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now onto deepexplain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797fc8c1-065f-470d-b1ed-a4d865a5b896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Load your pre-trained Keras model\n",
    "keras_model.save(\"keras_model\")\n",
    "#keras_model.save('./fc-task-decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f0edd-93cc-4015-a5ce-95d414113ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras_model.save('keras_model.h5')  # Save model in HDF5 format\n",
    "# binary data format that allows you to store the model architecture, weights, and other configuration details in a single file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da5de22-ee1e-450f-afad-15056c6964c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Keras model from the saved HDF5 file\n",
    "keras_model = keras.models.load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c924b3-e12e-4026-b985-3e3cd7ee8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1503/3193419636.py:2: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DeepExplain instance\n",
    "session = tf.compat.v1.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733718c3-b194-41ee-ad2f-a0bae06f5337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m keras_model\u001b[38;5;241m.\u001b[39minput\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Explain the model's predictions using DeepExplain\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrad*input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DeepExplain/deepexplain/tensorflow/methods.py:623\u001b[0m, in \u001b[0;36mDeepExplain.explain\u001b[0;34m(self, method, T, X, xs, ys, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, T, X, xs, ys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 623\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_explainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m explainer\u001b[38;5;241m.\u001b[39mrun(xs, ys, batch_size)\n",
      "File \u001b[0;32m~/DeepExplain/deepexplain/tensorflow/methods.py:608\u001b[0m, in \u001b[0;36mDeepExplain.get_explainer\u001b[0;34m(self, method, T, X, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m _GRAD_OVERRIDE_CHECKFLAG \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    607\u001b[0m _ENABLED_METHOD_CLASS \u001b[38;5;241m=\u001b[39m method_class\n\u001b[0;32m--> 608\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[43m_ENABLED_METHOD_CLASS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mkeras_learning_phase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_phase_placeholder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(_ENABLED_METHOD_CLASS, GradientBasedMethod) \u001b[38;5;129;01mand\u001b[39;00m _GRAD_OVERRIDE_CHECKFLAG \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    614\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepExplain detected you are trying to use an attribution method that requires \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    615\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradient override but the original gradient was used instead. You might have forgot to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    616\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(re)create your graph within the DeepExlain context. Results are not reliable!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/DeepExplain/deepexplain/tensorflow/methods.py:78\u001b[0m, in \u001b[0;36mAttributionMethod.__init__\u001b[0;34m(self, T, X, session, keras_learning_phase)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_shape)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# placeholder_from_data(ys) if ys is not None else 1.0  # Tensor that represents weights for T\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_attribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m session\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])\n\u001b[1;32m    118\u001b[0m ):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTFOpLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/base_layer_v1.py:898\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m cast_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    897\u001b[0m ):\n\u001b[0;32m--> 898\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:242\u001b[0m, in \u001b[0;36mTFOpLambda.__init__.<locals>._call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:279\u001b[0m, in \u001b[0;36mTFOpLambda._call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(\n\u001b[1;32m    272\u001b[0m     watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tape, tf\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# `name` passed (which is susceptible to producing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# multiple ops w/ the same name when the layer is reused)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 279\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])\n\u001b[1;32m    118\u001b[0m ):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTFOpLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/base_layer_v1.py:898\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m cast_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    897\u001b[0m ):\n\u001b[0;32m--> 898\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:242\u001b[0m, in \u001b[0;36mTFOpLambda.__init__.<locals>._call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:279\u001b[0m, in \u001b[0;36mTFOpLambda._call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(\n\u001b[1;32m    272\u001b[0m     watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tape, tf\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# `name` passed (which is susceptible to producing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# multiple ops w/ the same name when the layer is reused)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 279\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "    \u001b[0;31m[... skipping similar frames: Layer.__call__ at line 898 (365 times), TFOpLambda.__init__.<locals>._call_wrapper at line 242 (365 times), TFOpLambda._call_wrapper at line 279 (365 times), KerasOpDispatcher.handle at line 119 (365 times)]\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])\n\u001b[1;32m    118\u001b[0m ):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTFOpLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/base_layer_v1.py:898\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m cast_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    897\u001b[0m ):\n\u001b[0;32m--> 898\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:242\u001b[0m, in \u001b[0;36mTFOpLambda.__init__.<locals>._call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/layers/core/tf_op_layer.py:279\u001b[0m, in \u001b[0;36mTFOpLambda._call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(\n\u001b[1;32m    272\u001b[0m     watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tape, tf\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# `name` passed (which is susceptible to producing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# multiple ops w/ the same name when the layer is reused)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 279\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/keras_tensor.py:284\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are passing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an intermediate Keras symbolic \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.reshape`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs/outputs. You can work around \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call` and calling that layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon this symbolic input/output.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/keras/engine/keras_tensor.py:329\u001b[0m, in \u001b[0;36mKerasTensor.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     name_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, name=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKerasTensor(type_spec=\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43minferred_value_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msymbolic_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# Create a DeepExplain explainer using the Keras session\n",
    "with DeepExplain(session=session) as de:\n",
    "    # Load and preprocess the Fashion MNIST dataset\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    X_test = X_test.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Assuming you want to explain predictions for the first 10 images in the test set\n",
    "    num_samples = 10\n",
    "    input_data = X_test[:num_samples]  # Use the first 10 images as input_data\n",
    "\n",
    "    # Get the model's output tensor\n",
    "    output_tensor = keras_model.output\n",
    "    # Get the model's input tensor\n",
    "    input_tensor = keras_model.input\n",
    "    # Explain the model's predictions using DeepExplain\n",
    "    explanation = de.explain('grad*input', output_tensor, input_tensor, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e83f26-2c7d-4d95-adc5-d17a17fd9552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60149196-eaf0-486b-81e5-0fb1c55b10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use the explanation as needed\n",
    "print(explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
